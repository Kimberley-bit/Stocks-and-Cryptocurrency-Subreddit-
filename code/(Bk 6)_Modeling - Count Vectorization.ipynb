{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5626df1d",
   "metadata": {},
   "source": [
    "# Modeling - Count Vectorization (bk 6)\n",
    "\n",
    "#### In this Notebook:\n",
    "        6.1: Train, Test, Split\n",
    "        6.2: Bernoulli Naive Bayes\n",
    "            6.2.1: Bernoulli Naive Bayes\n",
    "            6.2.2: Multinomial Naive Bayes\n",
    "            6.2.3: Gaussian Naive Bayes\n",
    "            6.2.4: Optimisation of Bernoulli Naive Bayes\n",
    "        6.4: Logistic Regression\n",
    "            6.4.1: Model Evaluation\n",
    "        6.3: KNN Neighbor\n",
    "            6.3.1: Model Fitting and Evaluation\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be6116a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline, Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca29f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_counts_df = pd.read_csv('../data/X_counts_df_CV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2492b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = pd.read_csv ('../data/data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51b4882e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext_title</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stocks</td>\n",
       "      <td>I am earning very little at the moment but I w...</td>\n",
       "      <td>1626851004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stocks</td>\n",
       "      <td>The stocks I chose were aapl, net, asts, icln,...</td>\n",
       "      <td>1626847423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stocks</td>\n",
       "      <td>Retail owns the companies so it could happen i...</td>\n",
       "      <td>1626846017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stocks</td>\n",
       "      <td>Hi,\\n\\nI'm looking for the best software to tr...</td>\n",
       "      <td>1626845812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stocks</td>\n",
       "      <td>I'm not a car guy and I'm not an EV guy.  Def ...</td>\n",
       "      <td>1626840162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                     selftext_title  created_utc\n",
       "0    stocks  I am earning very little at the moment but I w...   1626851004\n",
       "1    stocks  The stocks I chose were aapl, net, asts, icln,...   1626847423\n",
       "2    stocks  Retail owns the companies so it could happen i...   1626846017\n",
       "3    stocks  Hi,\\n\\nI'm looking for the best software to tr...   1626845812\n",
       "4    stocks  I'm not a car guy and I'm not an EV guy.  Def ...   1626840162"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ec9ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the created_utc \n",
    "data_clean = data_clean.drop( ['created_utc'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3502d396",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stocks</td>\n",
       "      <td>I am earning very little at the moment but I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stocks</td>\n",
       "      <td>The stocks I chose were aapl, net, asts, icln,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stocks</td>\n",
       "      <td>Retail owns the companies so it could happen i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stocks</td>\n",
       "      <td>Hi,\\n\\nI'm looking for the best software to tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stocks</td>\n",
       "      <td>I'm not a car guy and I'm not an EV guy.  Def ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                     selftext_title\n",
       "0    stocks  I am earning very little at the moment but I w...\n",
       "1    stocks  The stocks I chose were aapl, net, asts, icln,...\n",
       "2    stocks  Retail owns the companies so it could happen i...\n",
       "3    stocks  Hi,\\n\\nI'm looking for the best software to tr...\n",
       "4    stocks  I'm not a car guy and I'm not an EV guy.  Def ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "534fe030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3395</th>\n",
       "      <td>CryptoCurrency</td>\n",
       "      <td>I’ve started seeing posts on here acknowledgin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3396</th>\n",
       "      <td>CryptoCurrency</td>\n",
       "      <td>Let me get started.\\n\\nIt was after the Snowde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>CryptoCurrency</td>\n",
       "      <td>I have been thinking about this for sometime a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>CryptoCurrency</td>\n",
       "      <td>I'm curious as to how mining and the price of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>CryptoCurrency</td>\n",
       "      <td>Hey guys, \\n\\nSo the post a few days ago about...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           subreddit                                     selftext_title\n",
       "3395  CryptoCurrency  I’ve started seeing posts on here acknowledgin...\n",
       "3396  CryptoCurrency  Let me get started.\\n\\nIt was after the Snowde...\n",
       "3397  CryptoCurrency  I have been thinking about this for sometime a...\n",
       "3398  CryptoCurrency  I'm curious as to how mining and the price of ...\n",
       "3399  CryptoCurrency  Hey guys, \\n\\nSo the post a few days ago about..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2cc7596",
   "metadata": {},
   "outputs": [],
   "source": [
    "di = {'stocks': 1, 'CryptoCurrency' :0}\n",
    "data_clean['subreddit'] = data_clean['subreddit'].map(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe32c310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3400, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba50b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning X and y \n",
    "X = X_counts_df\n",
    "y = data_clean['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3ac4c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3400, 23127)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b73bb7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3400,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dbad352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ef3bb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3395    0\n",
       "3396    0\n",
       "3397    0\n",
       "3398    0\n",
       "3399    0\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167a6ee6",
   "metadata": {},
   "source": [
    "#### Baseline score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aaea9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5\n",
       "1    0.5\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077d1a9d",
   "metadata": {},
   "source": [
    "### 6.1 Train, Test, Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b634052",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, stratify = y, random_state = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e0cc72",
   "metadata": {},
   "source": [
    "### 6.2 Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844dba9c",
   "metadata": {},
   "source": [
    "#### 6.2.1 Using Bernoulli Naive Bayes to predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe5fe1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB(binarize=True)\n",
      "0.7218487394957983\n",
      "0.7714285714285715\n",
      "0.7245098039215686\n",
      "0.7245098039215686\n"
     ]
    }
   ],
   "source": [
    "BernNB = BernoulliNB(binarize = True)\n",
    "BernNB.fit(X_train, y_train)\n",
    "print(BernNB)\n",
    "\n",
    "y_expect = y_test\n",
    "\n",
    "# Predicting Y = subreddit\n",
    "y_pred = BernNB.predict(X_test)\n",
    "\n",
    "# Cross-Validation\n",
    "print(cross_val_score(BernNB, X_train, y_train, cv = 5).mean())\n",
    "\n",
    "# Accuracy score of train\n",
    "print(BernNB.score(X_train, y_train))\n",
    "\n",
    "# Accuracy score of test\n",
    "print(BernNB.score(X_test, y_test))\n",
    "\n",
    "# Accuracy for y_expect and y_pred\n",
    "print(accuracy_score(y_expect, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335aea26",
   "metadata": {},
   "source": [
    "#### 6.2.2 Using Multinomial Naive Bayes to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3e87260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB()\n",
      "0.7546218487394958\n",
      "0.7777310924369748\n",
      "0.7637254901960784\n",
      "0.7637254901960784\n"
     ]
    }
   ],
   "source": [
    "MultiNB = MultinomialNB()\n",
    "MultiNB.fit(X_train, y_train)\n",
    "print(MultiNB)\n",
    "\n",
    "# Predicting Y = subreddit \n",
    "y_pred = MultiNB.predict(X_test)\n",
    "\n",
    "# Cross-Validation\n",
    "print(cross_val_score(MultiNB, X_train, y_train, cv = 5).mean())\n",
    "\n",
    "# Accuracy score of train\n",
    "print(MultiNB.score(X_train, y_train))\n",
    "\n",
    "# Accuracy score of test\n",
    "print(MultiNB.score(X_test, y_test))\n",
    "\n",
    "# Accuracy for y_test and y_pred\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cfd3e5",
   "metadata": {},
   "source": [
    "#### 6.2.3 Using Gaussian Naive Bayes to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bedb5702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "0.7100840336134454\n",
      "0.7890756302521008\n",
      "0.7186274509803922\n",
      "0.7186274509803922\n"
     ]
    }
   ],
   "source": [
    "GausNB = GaussianNB()\n",
    "GausNB.fit(X_train, y_train)\n",
    "print(GausNB)\n",
    "\n",
    "# Predicting Y = subreddit \n",
    "y_pred = GausNB.predict(X_test)\n",
    "\n",
    "# Cross-Validation\n",
    "print(cross_val_score(GausNB, X_train, y_train, cv = 5).mean())\n",
    "\n",
    "# Accuracy score of train\n",
    "print(GausNB.score(X_train, y_train))\n",
    "\n",
    "# Accuracy score of test\n",
    "print(GausNB.score(X_test, y_test))\n",
    "\n",
    "# Accuracy for y_test and y_pred\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32506ea0",
   "metadata": {},
   "source": [
    "#### 6.2.4 Using optimisation of Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5768fa8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB(binarize=0.1)\n",
      "0.7638655462184873\n",
      "0.8445378151260504\n",
      "0.7823529411764706\n",
      "0.7823529411764706\n"
     ]
    }
   ],
   "source": [
    "BernNB = BernoulliNB(binarize = 0.1)\n",
    "BernNB.fit(X_train, y_train)\n",
    "print(BernNB)\n",
    "\n",
    "y_expect = y_test\n",
    "\n",
    "# Predicting Y = subreddit \n",
    "y_pred = BernNB.predict(X_test)\n",
    "\n",
    "# Cross-Validation\n",
    "print(cross_val_score(BernNB, X_train, y_train, cv = 5).mean())\n",
    "\n",
    "# Accuracy score of train\n",
    "print(BernNB.score(X_train, y_train))\n",
    "\n",
    "# Accuracy score of test\n",
    "print(BernNB.score(X_test, y_test))\n",
    "\n",
    "# Accuracy for y_expect and y_pred\n",
    "print(accuracy_score(y_expect, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b246dfb",
   "metadata": {},
   "source": [
    "#### Model Evaluation of Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5367131d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB()\n"
     ]
    }
   ],
   "source": [
    "MultiNB = MultinomialNB()\n",
    "MultiNB.fit(X_train, y_train)\n",
    "print(MultiNB)\n",
    "\n",
    "# predicting Y = subreddit \n",
    "y_pred = MultiNB.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87376982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.96      0.80       510\n",
      "           1       0.94      0.56      0.71       510\n",
      "\n",
      "    accuracy                           0.76      1020\n",
      "   macro avg       0.81      0.76      0.75      1020\n",
      "weighted avg       0.81      0.76      0.75      1020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf992dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.7637254901960784\n",
      "precision score: 0.9381107491856677\n",
      "recall score: 0.5647058823529412\n",
      "specificity score: 0.9627450980392157\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# scores\n",
    "accuracy_score = accuracy_score(y_test, y_pred)\n",
    "precision_score = precision_score(y_test, y_pred)\n",
    "recall_score = recall_score = recall_score(y_test, y_pred)\n",
    "specificity_score = tn / (tn + fp)\n",
    "\n",
    "print('accuracy score: ' + str(accuracy_score))\n",
    "print('precision score: ' + str(precision_score))\n",
    "print('recall score: ' + str(recall_score))\n",
    "print('specificity score: ' + str(specificity_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09980d2",
   "metadata": {},
   "source": [
    "### 6.3 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93fa1c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, stratify = y, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cd7e347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg = LogisticRegression(solver = 'liblinear')\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e7517ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LogReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c837c86d",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca6bd83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       510\n",
      "           1       0.99      0.97      0.98       510\n",
      "\n",
      "    accuracy                           0.98      1020\n",
      "   macro avg       0.98      0.98      0.98      1020\n",
      "weighted avg       0.98      0.98      0.98      1020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30e10258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1175,   15],\n",
       "       [  23, 1167]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = cross_val_predict(LogReg, X_train, y_train, cv = 5)\n",
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571b9744",
   "metadata": {},
   "source": [
    "### 6.4 KNN Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78e481f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, stratify = y, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25a8eba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74fc0d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5579831932773109"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate KNN\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "# Cross-validation\n",
    "cross_val_score(knn, X_train_sc, y_train, cv = 5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ef4793",
   "metadata": {},
   "source": [
    "#### 6.4.1 Model Fitting and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31541751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.980672268907563"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train_sc, y_train)\n",
    "knn.score(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0d2bedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5852941176470589"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2414cb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5107843137254902"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn, X_test_sc, y_test, cv = 5).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
